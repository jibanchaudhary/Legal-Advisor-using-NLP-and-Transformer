{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "from langchain.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tg/zl7s2ps552q98skjx109t19c0000gn/T/ipykernel_2454/2960928784.py:2: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  mixtral_llm = Ollama(model=\"mistral:7b\", base_url=\"http://localhost:11434\")\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Ollama model\n",
    "mixtral_llm = Ollama(model=\"mistral:7b\", base_url=\"http://localhost:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt for filtering\n",
    "filter_prompt = PromptTemplate(\n",
    "    template=('''\n",
    "        You are a legal query classifier. Strictly categorize the following query as either 'Legal' or 'Non-Legal' based on cybercrime relevance:\n",
    "\n",
    "        **Classify as 'Legal' ONLY if it explicitly involves:**\n",
    "        1. Unauthorized digital access (hacking, account takeover, system intrusion)\n",
    "        2. Online financial crimes (scams, phishing, cryptocurrency fraud)\n",
    "        3. Data compromise (breaches, leaks, doxxing, sensitive info exposure)\n",
    "        4. Identity-based crimes (theft, impersonation, fake profiles)\n",
    "        5. Digital harassment (cyberbullying, revenge porn, threats via platforms)\n",
    "        6. Technology-facilitated crimes (dark web activities, malware distribution)\n",
    "        7. Specific legal actions/impacts (arrests, lawsuits, regulatory violations)\n",
    "\n",
    "        **Classify as 'Non-Legal' for:**\n",
    "        1. General tech issues (password reset, software installs, performance issues)\n",
    "        2. Basic internet safety questions without specific incidents\n",
    "        3. Non-cyber legal matters (physical crimes, family law, contracts)\n",
    "        4. Hypothetical/theoretical scenarios without real-world impact\n",
    "        5. Platform usage questions (account deletion, feature inquiries)\n",
    "        6. General tech discussions (AI ethics, cryptocurrency concepts)\n",
    "        7. Non-actionable complaints (spam emails without financial loss)\n",
    "\n",
    "        **Decision Guidelines:**\n",
    "        - Assume malicious intent for account access issues\n",
    "        - Require explicit mention of harm for financial/identity matters\n",
    "        - Treat data leaks as legal only if personal/sensitive info involved\n",
    "        - Ignore jurisdiction considerations - focus on incident nature\n",
    "        - Default to 'Non-Legal' for ambiguous cases\n",
    "\n",
    "        **Response Format:** \n",
    "        Reply ONLY with 'Legal' or 'Non-Legal' - no explanations.\n",
    "\n",
    "        Query: {input_text}\n",
    "    '''),\n",
    "    input_variables=['input_text'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legal\n",
      "Non-Legal\n",
      "Legal\n"
     ]
    }
   ],
   "source": [
    "def filter_query(input_text):\n",
    "    response = mixtral_llm(filter_prompt.format(input_text=input_text))\n",
    "    return response.strip()\n",
    "\n",
    "print(filter_query(\"My facebook got hacked\"))\n",
    "print(filter_query(\"Hey how are you doing\"))\n",
    "print(filter_query(\"hey! good morning ,my facebook is compromisted\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I help you today? Let's make your day a little bit brighter. What would you like to know or talk about? I'm here to assist with any questions you have, from the mundane to the extraordinary. ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "def general_convo(input_text):\n",
    "    response = mixtral_llm(input_text)\n",
    "    return response.strip()\n",
    "print(general_convo(\"Hey\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
